import numpy as np
from skimage.draw import disk, line
from sklearn.model_selection import train_test_split
import torch
from torch.utils.data import Dataset, DataLoader

# =====================
# DEFECT GENERATION FUNCTIONS
# =====================
def add_dust_defect(field, x, center, radius):
    """Circular opaque defect"""
    mask = np.ones_like(x)
    distance = np.abs(x - center)
    mask[distance < radius] = 0
    return field * mask

def add_scratch_defect(field, x, start, end, width):
    """Linear scratch defect"""
    mask = np.ones_like(x)
    for i in range(len(x)):
        if abs(x[i] - start) < width/2 or abs(x[i] - end) < width/2:
            mask[i] = 0
        elif (x[i] > start) and (x[i] < end):
            mask[i] = 0
    return field * mask

def add_bubble_defect(field, x, center, radius):
    """Phase distortion defect (coating bubble)"""
    phase_distortion = np.zeros_like(x)
    distance = np.abs(x - center)
    phase_distortion[distance < radius] = np.pi/2  # Quarter-wave distortion
    return field * np.exp(1j * phase_distortion)

# =====================
# DATASET GENERATION
# =====================
def generate_defect_samples(num_samples=1000):
    X = []
    y = []
    
    defect_types = ['dust', 'scratch', 'bubble']
    sizes = ['small', 'medium', 'large']
    positions = ['center', 'mid', 'edge']
    
    for _ in range(num_samples):
        # Random beam parameters
        wavelength = np.random.choice([632e-9, 1550e-9])
        beam_waist = np.random.uniform(40e-6, 60e-6)
        
        # Random defect parameters
        defect_type = np.random.choice(defect_types)
        size = np.random.choice(sizes)
        position = np.random.choice(positions)
        
        # Convert to physical parameters
        if size == 'small':
            radius = np.random.uniform(5e-6, 15e-6)
            width = 2e-6
        elif size == 'medium':
            radius = np.random.uniform(15e-6, 30e-6)
            width = 5e-6
        else:  # large
            radius = np.random.uniform(30e-6, 50e-6)
            width = 8e-6
            
        if position == 'center':
            center = 0
            start, end = -50e-6, 50e-6
        elif position == 'mid':
            center = np.random.choice([-1,1]) * 40e-6
            start, end = center-30e-6, center+30e-6
        else:  # edge
            center = np.random.choice([-1,1]) * 75e-6
            start, end = center-20e-6, center+20e-6
        
        # Simulate beam with defect
        x = np.linspace(-100e-6, 100e-6, 256)
        field = gaussian_beam(x, 0, beam_waist, wavelength)
        
        # Apply defect
        if defect_type == 'dust':
            field = add_dust_defect(field, x, center, radius)
        elif defect_type == 'scratch':
            field = add_scratch_defect(field, x, start, end, width)
        else:  # bubble
            field = add_bubble_defect(field, x, center, radius)
        
        # Propagate to focus
        field = propagate_fresnel(field, x, wavelength, focal_length=0.05)
        
        # Store intensity and phase
        X.append(np.stack([np.abs(field)**2, np.angle(field)]))  # 2-channel input
        y.append([defect_types.index(defect_type), 
                 sizes.index(size), 
                 positions.index(position)])
    
    return np.array(X), np.array(y)

# Generate dataset
X, y = generate_defect_samples(5000)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

# =====================
# PYTORCH DATASET
# =====================
class OpticsDefectDataset(Dataset):
    def __init__(self, X, y):
        self.X = torch.FloatTensor(X)
        self.y = torch.LongTensor(y)
        
    def __len__(self):
        return len(self.X)
    
    def __getitem__(self, idx):
        return self.X[idx], self.y[idx]

train_dataset = OpticsDefectDataset(X_train, y_train)
test_dataset = OpticsDefectDataset(X_test, y_test)

# Data loaders
batch_size = 32
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=batch_size)

import torch.nn as nn
import torch.nn.functional as F

class DefectClassifier(nn.Module):
    def __init__(self):
        super().__init__()
        
        # Shared feature extractor
        self.conv1 = nn.Conv2d(2, 32, 3, padding=1)  # 2 channels: intensity + phase
        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)
        self.pool = nn.MaxPool2d(2, 2)
        self.dropout = nn.Dropout(0.25)
        
        # Multi-task heads
        self.type_head = nn.Sequential(
            nn.Linear(64*64*64, 128),
            nn.ReLU(),
            nn.Linear(128, 3)  # 3 defect types
        )
        
        self.size_head = nn.Sequential(
            nn.Linear(64*64*64, 128),
            nn.ReLU(),
            nn.Linear(128, 3)  # 3 size classes
        )
        
        self.position_head = nn.Sequential(
            nn.Linear(64*64*64, 128),
            nn.ReLU(),
            nn.Linear(128, 3)  # 3 position classes
        )
    
    def forward(self, x):
        # Shared features
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = self.dropout(x)
        x = torch.flatten(x, 1)
        
        # Multi-task predictions
        type_pred = self.type_head(x)
        size_pred = self.size_head(x)
        position_pred = self.position_head(x)
        
        return type_pred, size_pred, position_pred

model = DefectClassifier()

def train_model(model, train_loader, test_loader, epochs=20):
    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
    type_criterion = nn.CrossEntropyLoss()
    size_criterion = nn.CrossEntropyLoss()
    position_criterion = nn.CrossEntropyLoss()
    
    for epoch in range(epochs):
        model.train()
        train_loss = 0
        
        for X_batch, y_batch in train_loader:
            optimizer.zero_grad()
            
            # Forward pass
            type_pred, size_pred, position_pred = model(X_batch)
            
            # Compute losses
            type_loss = type_criterion(type_pred, y_batch[:,0])
            size_loss = size_criterion(size_pred, y_batch[:,1])
            position_loss = position_criterion(position_pred, y_batch[:,2])
            total_loss = type_loss + size_loss + position_loss
            
            # Backward pass
            total_loss.backward()
            optimizer.step()
            train_loss += total_loss.item()
        
        # Validation
        model.eval()
        val_loss = 0
        correct = 0
        total = 0
        
        with torch.no_grad():
            for X_batch, y_batch in test_loader:
                type_pred, size_pred, position_pred = model(X_batch)
                
                # Calculate validation loss
                type_loss = type_criterion(type_pred, y_batch[:,0])
                size_loss = size_criterion(size_pred, y_batch[:,1])
                position_loss = position_criterion(position_pred, y_batch[:,2])
                val_loss += (type_loss + size_loss + position_loss).item()
                
                # Calculate accuracy
                _, type_pred = torch.max(type_pred, 1)
                _, size_pred = torch.max(size_pred, 1)
                _, position_pred = torch.max(position_pred, 1)
                
                correct += (type_pred == y_batch[:,0]).sum().item()
                correct += (size_pred == y_batch[:,1]).sum().item()
                correct += (position_pred == y_batch[:,2]).sum().item()
                total += 3 * y_batch.size(0)
        
        print(f'Epoch {epoch+1}/{epochs} | '
              f'Train Loss: {train_loss/len(train_loader):.4f} | '
              f'Val Loss: {val_loss/len(test_loader):.4f} | '
              f'Accuracy: {100*correct/total:.2f}%')

train_model(model, train_loader, test_loader)
